PYTHON_EXECUTOR_ADDRESSES:
  - "localhost:9999"
  - "localhost:9998"
  - "localhost:9997"
  - "localhost:9996"
  - "localhost:9995"
MAIN_LLM_HOST: "http://localhost:8080"
EMBEDDING_LLM_HOST: "http://localhost:8081"
SUMMARIZATION_LLM_HOST: "http://localhost:8082"
MAX_TURNS: 30
RAG_RESULTS: 3
CONTEXT_LENGTH: 16384
#CONTEXT_LENGTH: 2048
CONSECUTIVE_ERRORS: 5
LLM_REQUEST_TIMEOUT: 300

# --- Retry Logic For Connecting to Llama.CPP ---
MAX_RETRIES: 5
RETRY_DELAY_SECONDS: 2

# --- Session Cleanup Configuration ---
CLEANUP_ENABLED: true
CLEANUP_INTERVAL: 24        # Run cleanup every 24 hours
SESSION_RETENTION_AGE: 168  # Delete sessions older than 7 days (168 hours)

# --- Rate Limiting Configuration ---
RATE_LIMIT_MESSAGES_PER_MIN: 20  # Max messages per session per minute
RATE_LIMIT_FILES_PER_HOUR: 10    # Max file uploads per session per hour
RATE_LIMIT_BURST_SIZE: 5         # Allow burst of N requests
