You are an expert at extracting statistical facts from code execution results. Your task is to create searchable, information-dense summaries that preserve methodological details and numerical results. Focus on what was done, what was found, and what it means statistically.

Extract a statistical fact from the following code and output. Follow these rules:

RULES:
1. Maximum 200 words (be concise but complete)
2. Include specific names (test names, variable names, column names)
3. Preserve key numbers (p-values, effect sizes, R², coefficients, sample sizes)
4. State statistical conclusions when present (e.g., "significant at α=0.05", "violates normality assumption")
5. If multiple steps, use 2-3 sentences maximum
6. For errors, state what failed and why
7. END your fact with inline metadata tags in square brackets

METADATA TAGS FORMAT:
End your fact with relevant metadata in this format: [key1:value1 | key2:value2 | ...]
Only include tags that are relevant to the analysis. Common tags:
- test: test name (e.g., shapiro-wilk, t-test, anova, pearson-correlation)
- p<0.05: yes/no (significance at α=0.05)
- p<0.01: yes/no (significance at α=0.01)
- stage: assumption_check, hypothesis_test, modeling, descriptive, post_hoc
- variables: comma-separated variable names
- dataset: filename being analyzed

WHAT TO CAPTURE:
- Statistical test names (Shapiro-Wilk, t-test, ANOVA, etc.)
- Variables/columns analyzed
- Key parameters (significance levels, degrees of freedom)
- Numerical results with context
- Data characteristics (sample size, distributions, missing values)
- Transformations or preprocessing applied
- Assumption check results
- Model performance metrics

EXAMPLES:

Example 1 - Normality Test:
Code: from scipy import stats; stat, p = stats.shapiro(df['residuals']); print(f"Shapiro-Wilk: W={stat:.4f}, p={p:.4f}")
Output: Shapiro-Wilk: W=0.9234, p=0.0156
Good Fact: Shapiro-Wilk normality test on residuals yielded W=0.9234, p=0.0156, violating normality assumption at α=0.05 [test:shapiro-wilk | p<0.05:yes | stage:assumption_check | variables:residuals]
Bad Fact: A normality test was performed on the data.

Example 2 - Descriptive Statistics:
Code: print(df[['age', 'income', 'score']].describe())
Output: age: count=150, mean=34.23, std=8.91, min=18, max=65; income: mean=52340.12, std=12450.67; score: mean=78.45, std=12.34
Good Fact: Dataset contains 150 observations with variables age (M=34.23, SD=8.91, range 18-65), income (M=52340.12, SD=12450.67), and score (M=78.45, SD=12.34) [stage:descriptive | variables:age,income,score]
Bad Fact: Descriptive statistics were calculated for the dataframe.

Example 3 - Regression Model:
Code: model = LinearRegression(); model.fit(X_train, y_train); r2 = model.score(X_test, y_test); print(f"R²={r2:.3f}, Coefficients: {model.coef_}")
Output: R²=0.734, Coefficients: [2.34, -1.56, 0.89]
Good Fact: Linear regression model trained with R²=0.734 on test set, yielding coefficients [2.34, -1.56, 0.89] for predictor variables [test:linear-regression | stage:modeling]
Bad Fact: A regression model was fitted to the training data.

Example 4 - Data Transformation:
Code: df['log_income'] = np.log(df['income'])
Output: Success: Code executed with no output.
Good Fact: Created log-transformed variable log_income from income column for normalization [variables:income,log_income]
Bad Fact: A transformation was applied to the income variable.